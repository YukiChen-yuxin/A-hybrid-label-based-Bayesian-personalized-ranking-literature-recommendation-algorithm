{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuki\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\yuki\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\yuki\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\yuki\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\yuki\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\yuki\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuki\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "download=pd.read_csv(\"E:\\\\2020 慧源共享·数据悦读第二届高校开放数据创新研究大赛\\\\data\\\\数据\\\\下载行为日志_个人用户.csv\",error_bad_lines=False)\n",
    "see=pd.read_csv(\"E:\\\\2020 慧源共享·数据悦读第二届高校开放数据创新研究大赛\\\\data\\\\数据\\\\浏览行为日志_个人用户.csv\",error_bad_lines=False)\n",
    "see=see.drop(columns=['user_type','date_time','article_title','keywords','author','unit','province','classcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6769978</td>\n",
       "      <td>9fbc355f2519fc63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7427381</td>\n",
       "      <td>ebb77885bf041c50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7461623</td>\n",
       "      <td>86d5f40d3be7d711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8443319</td>\n",
       "      <td>7dec20b3e3230936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8443319</td>\n",
       "      <td>7dec20b3e3230936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683811</th>\n",
       "      <td>zyzg201708012</td>\n",
       "      <td>81a8195e5ea6a14d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683812</th>\n",
       "      <td>zyzg201708012</td>\n",
       "      <td>81a8195e5ea6a14d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683813</th>\n",
       "      <td>zyzg201708012</td>\n",
       "      <td>81a8195e5ea6a14d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683814</th>\n",
       "      <td>zyzg201708012</td>\n",
       "      <td>81a8195e5ea6a14d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683815</th>\n",
       "      <td>zyzg201708012</td>\n",
       "      <td>81a8195e5ea6a14d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683816 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           article_id           user_id  type\n",
       "0             6769978  9fbc355f2519fc63     1\n",
       "1             7427381  ebb77885bf041c50     1\n",
       "2             7461623  86d5f40d3be7d711     1\n",
       "3             8443319  7dec20b3e3230936     1\n",
       "4             8443319  7dec20b3e3230936     1\n",
       "...               ...               ...   ...\n",
       "683811  zyzg201708012  81a8195e5ea6a14d     1\n",
       "683812  zyzg201708012  81a8195e5ea6a14d     1\n",
       "683813  zyzg201708012  81a8195e5ea6a14d     1\n",
       "683814  zyzg201708012  81a8195e5ea6a14d     1\n",
       "683815  zyzg201708012  81a8195e5ea6a14d     1\n",
       "\n",
       "[683816 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0120180804676542</td>\n",
       "      <td>4130035b8a4b59c0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0120180804676542</td>\n",
       "      <td>4130035b8a4b59c0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0120180804985060</td>\n",
       "      <td>96758755a2c52217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0120180804985060</td>\n",
       "      <td>de46b376f881b6d5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0120180805054765</td>\n",
       "      <td>7b28bde83d4b7414</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832953</th>\n",
       "      <td>zzgy201810001</td>\n",
       "      <td>1af81811f3fc4cf6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832954</th>\n",
       "      <td>zzjs201901022</td>\n",
       "      <td>93abfee3bc085cbf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832955</th>\n",
       "      <td>zzyfl200102021</td>\n",
       "      <td>c26a04c676555c87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832956</th>\n",
       "      <td>zzyzdh200203008</td>\n",
       "      <td>c9d2abe18e7d8f33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832957</th>\n",
       "      <td>zzyzdh200203008</td>\n",
       "      <td>c9d2abe18e7d8f33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832958 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              article_id           user_id type\n",
       "0       0120180804676542  4130035b8a4b59c0    2\n",
       "1       0120180804676542  4130035b8a4b59c0    2\n",
       "2       0120180804985060  96758755a2c52217    2\n",
       "3       0120180804985060  de46b376f881b6d5    2\n",
       "4       0120180805054765  7b28bde83d4b7414    2\n",
       "...                  ...               ...  ...\n",
       "832953     zzgy201810001  1af81811f3fc4cf6    2\n",
       "832954     zzjs201901022  93abfee3bc085cbf    2\n",
       "832955    zzyfl200102021  c26a04c676555c87    2\n",
       "832956   zzyzdh200203008  c9d2abe18e7d8f33    2\n",
       "832957   zzyzdh200203008  c9d2abe18e7d8f33    2\n",
       "\n",
       "[832958 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download.set_index(['user_id'],inplace=True)\n",
    "download=download.sort_index(level='user_id')\n",
    "download=download.reset_index()\n",
    "down2=download.groupby(['user_id','article_id']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003bc49a090acd4</td>\n",
       "      <td>xrwk201711002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003eb82209c8376</td>\n",
       "      <td>hainanyx201716013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003eb82209c8376</td>\n",
       "      <td>hnyxyj201607032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003eb82209c8376</td>\n",
       "      <td>tlsjyyj201919043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003eb82209c8376</td>\n",
       "      <td>yjyx201907014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352886</th>\n",
       "      <td>fffc9c4d5a9749bf</td>\n",
       "      <td>xxjsjy201808031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352887</th>\n",
       "      <td>fffd41718f68607a</td>\n",
       "      <td>spyjykf201418099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352888</th>\n",
       "      <td>fffef9619c8660b6</td>\n",
       "      <td>mysj201818089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352889</th>\n",
       "      <td>ffff2b46450b76a8</td>\n",
       "      <td>lpssfgdzkxxxb201204014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352890</th>\n",
       "      <td>fffff213700eebf2</td>\n",
       "      <td>zgszyx201402023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352891 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id              article_id  count\n",
       "0       0003bc49a090acd4           xrwk201711002      3\n",
       "1       0003eb82209c8376       hainanyx201716013      1\n",
       "2       0003eb82209c8376         hnyxyj201607032      1\n",
       "3       0003eb82209c8376        tlsjyyj201919043      1\n",
       "4       0003eb82209c8376           yjyx201907014      1\n",
       "...                  ...                     ...    ...\n",
       "352886  fffc9c4d5a9749bf         xxjsjy201808031      1\n",
       "352887  fffd41718f68607a        spyjykf201418099      1\n",
       "352888  fffef9619c8660b6           mysj201818089      1\n",
       "352889  ffff2b46450b76a8  lpssfgdzkxxxb201204014      3\n",
       "352890  fffff213700eebf2         zgszyx201402023      1\n",
       "\n",
       "[352891 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "see.set_index(['user_id'],inplace=True)\n",
    "see=see.sort_index(level='user_id')\n",
    "see=see.reset_index()\n",
    "see2=see.groupby(['user_id','article_id']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e6436d10673</td>\n",
       "      <td>csjsllyj2011231633</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00003e6436d10673</td>\n",
       "      <td>zgkjzh201224159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00004f36d33c75e6</td>\n",
       "      <td>Y2323894</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000786d80357b13</td>\n",
       "      <td>dnbcjqywh201021005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000786d80357b13</td>\n",
       "      <td>kxyxxh201720026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584942</th>\n",
       "      <td>ffff2b46450b76a8</td>\n",
       "      <td>jyjxlt201347200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584943</th>\n",
       "      <td>ffff2b46450b76a8</td>\n",
       "      <td>lpssfgdzkxxxb201204014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584944</th>\n",
       "      <td>ffff9c12c9b929d7</td>\n",
       "      <td>ckxx201924031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584945</th>\n",
       "      <td>ffff9c12c9b929d7</td>\n",
       "      <td>danddhj201916083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584946</th>\n",
       "      <td>ffff9c12c9b929d7</td>\n",
       "      <td>yygllt201901001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584947 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id              article_id  count\n",
       "0       00003e6436d10673      csjsllyj2011231633      2\n",
       "1       00003e6436d10673         zgkjzh201224159      1\n",
       "2       00004f36d33c75e6                Y2323894      2\n",
       "3       0000786d80357b13      dnbcjqywh201021005      1\n",
       "4       0000786d80357b13         kxyxxh201720026      1\n",
       "...                  ...                     ...    ...\n",
       "584942  ffff2b46450b76a8         jyjxlt201347200      1\n",
       "584943  ffff2b46450b76a8  lpssfgdzkxxxb201204014      1\n",
       "584944  ffff9c12c9b929d7           ckxx201924031      1\n",
       "584945  ffff9c12c9b929d7        danddhj201916083      1\n",
       "584946  ffff9c12c9b929d7         yygllt201901001      1\n",
       "\n",
       "[584947 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''action={}\n",
    "\n",
    "I=range(down2.index.size)\n",
    "for i in I:\n",
    "    user_id=down2.loc[i,'user_id']\n",
    "    article=down2.loc[i,'article_id']\n",
    "    num=down2.loc[i,'count']\n",
    "    if user_id not in action.keys():\n",
    "        action[user_id]={}\n",
    "        action[user_id]['下载的文章id']=[]\n",
    "        action[user_id]['下载次数']=[]\n",
    "        action[user_id]['下载的文章id'].append(article)\n",
    "        action[user_id]['下载次数'].append(num)\n",
    "    else:\n",
    "        action[user_id]['下载的文章id'].append(article)\n",
    "        action[user_id]['下载次数'].append(num)\n",
    "        \n",
    "I=range(see2.index.size)\n",
    "for i in I:\n",
    "    user_id=see2.loc[i,'user_id']\n",
    "    article=see2.loc[i,'article_id']\n",
    "    num=see2.loc[i,'count']\n",
    "    if user_id not in action.keys():\n",
    "        action[user_id]={}\n",
    "        action[user_id]['浏览的文章id']=[]\n",
    "        action[user_id]['浏览次数']=[]\n",
    "        action[user_id]['浏览的文章id'].append(article)\n",
    "        action[user_id]['浏览次数'].append(num)\n",
    "    else:\n",
    "        if '浏览的文章id' not in action[user_id]:\n",
    "            action[user_id]['浏览的文章id']=[]\n",
    "            action[user_id]['浏览次数']=[]\n",
    "            action[user_id]['浏览的文章id'].append(article)\n",
    "            action[user_id]['浏览次数'].append(num)\n",
    "        else:\n",
    "            action[user_id]['浏览的文章id'].append(article)\n",
    "            action[user_id]['浏览次数'].append(num)            \n",
    "            \n",
    "data_action=pd.DataFrame(action)\n",
    "data_action2=pd.DataFrame(data_action.values.T,index=data_action.columns,columns=data_action.index)\n",
    "\n",
    "outputpath='E:\\\\2020 慧源共享·数据悦读第二届高校开放数据创新研究大赛\\\\data\\\\数据\\\\用户行为次数.csv'\n",
    "data_action2.to_csv(outputpath,sep=',',index=False,header=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "b=[]\n",
    "for x in list(seeuser)[:20000]:\n",
    "    if x in list(downuser):\n",
    "        b.append(x)\n",
    "        \n",
    "for x in list(seeuser)[20000:40000]:\n",
    "    if x in list(downuser):\n",
    "        b.append(x)    \n",
    "        \n",
    "for x in list(seeuser)[40000:60000]:\n",
    "    if x in list(downuser):\n",
    "        b.append(x)\n",
    "        \n",
    "for x in list(seeuser)[60000:100000]:\n",
    "    if x in list(downuser):\n",
    "        b.append(x)\n",
    "        \n",
    "for x in list(seeuser)[100000:130000]:\n",
    "    if x in list(downuser):\n",
    "        b.append(x)\n",
    "        \n",
    "for x in list(seeuser)[130000:]:\n",
    "    if x in list(downuser):\n",
    "        b.append(x)\n",
    "        \n",
    "col_name=['user']\n",
    "# 先转为DataFrame格式\n",
    "df = pd.DataFrame(columns=col_name, data=b)\n",
    "# index=False表示存储csv时没有默认的id索引\n",
    "df.to_csv(\"E:/2020 慧源共享·数据悦读第二届高校开放数据创新研究大赛/data/chongfu.csv\", encoding='utf-8', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artical=set(list(down2['article_id'].values)+list(see2['article_id'].values))\n",
    "users=set(list(down2['user_id'].values)+list(see2['user_id'].values))\n",
    "downuser=set(list(down2['user_id'].values))\n",
    "seeuser=set(list(see2['user_id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artical_list=list(artical)\n",
    "artical_list.sort(reverse=False)\n",
    "\n",
    "users_list=list(users)\n",
    "users_list.sort(reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207764"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737767"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user和article转化成数据框\n",
    "user_frame=pd.DataFrame(users_list,columns=['用户'])\n",
    "article_frame=pd.DataFrame(artical_list,columns=['论文'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#把用户和文章对应的序号做出来\n",
    "users_list_num=[]\n",
    "count_1=0\n",
    "for u in users_list:\n",
    "    users_list_num.append(count_1)\n",
    "    count_1+=1\n",
    "    \n",
    "artical_list_num=[]\n",
    "count_2=0\n",
    "for a in artical_list:\n",
    "    artical_list_num.append(count_2)\n",
    "    count_2+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''#建立一个有用户有下载浏览的文章号的字典\n",
    "user_ratings={}.fromkeys(users_list_num,[])'''\n",
    "user_ratings={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for user in users_list:\n",
    "    index=[]\n",
    "    value=[]\n",
    "    #找数据框中有这个userid的行索引,设成列表\n",
    "    index=down2[(down2['user_id'].values==user)].index.tolist()\n",
    "    #用户对应的论文id放到临时沦为id列表里，由于down2和see2数据框以实现去重\n",
    "    #所以不需要检查是否有多个重复值进入\n",
    "    for loc in index:\n",
    "        value.append(down2.loc[loc,'article_id'])\n",
    "    \n",
    "    down2=down2.drop(index)\n",
    "   \n",
    "    #找数据框中有这个userid的行索引,设成列表\n",
    "    index=see2[(see2['user_id'].values==user)].index.tolist()\n",
    "    #用户对应的论文id放到字典里\n",
    "    for loc in index:\n",
    "        #检查是否有重复值\n",
    "        if see2.loc[loc,'article_id'] not in value:\n",
    "            value.append(see2.loc[loc,'article_id'])\n",
    "    \n",
    "    see2=see2.drop(index)\n",
    "    \n",
    "    loc_u=users_list.index(user)\n",
    "    user_ratings[loc_u]=[]\n",
    "    for v in value:\n",
    "        loc_a=artical_list.index(v)\n",
    "        #存入用户对应的序号和文章对应的序号\n",
    "        user_ratings[loc_u].append(loc_a)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#生成的字典存成txt的方法\n",
    "f=open('总用户字典.txt','w')\n",
    "f.write(str(user_ratings))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#筛选满足条件的 行动>1且有行动\n",
    "for k in list(user_ratings.keys()):\n",
    "    if len(user_ratings[k])==0:\n",
    "        del user_ratings[k]\n",
    "        continue\n",
    "    elif len(user_ratings[k])==1:\n",
    "        del user_ratings[k]\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#生成的字典存成txt的方法\n",
    "f=open('temp.txt','w')\n",
    "f.write(str(user_ratings))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存成txt的文件重新生成字典的方法\n",
    "f=open('temp.txt','r')\n",
    "a=f.read()\n",
    "user_ratings=eval(a)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_test(user_ratings):\n",
    "    \"\"\"\n",
    "    对每一个用户u，在user_ratings中随机找到他评分过的一部电影i,保存在user_ratings_test，我们为每个用户取出的这一个电影，是不会在训练集中训练到的，作为测试集用。\n",
    "    \"\"\"\n",
    "    user_test = dict()\n",
    "    for u,i_list in user_ratings.items():\n",
    "        user_test[u] = random.sample(user_ratings[u],1)[0]\n",
    "    return user_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_batch(user_ratings,user_ratings_test,item_count,batch_size=512):\n",
    "    \"\"\"\n",
    "    构造训练用的三元组\n",
    "    对于随机抽出的用户u，i可以从user_ratings随机抽出，而j也是从总的论文集中随机抽出\n",
    "    当然j必须保证(u,j)不在user_ratings中\n",
    "\n",
    "    \"\"\"\n",
    "    t = []\n",
    "    for b in range(batch_size):\n",
    "        u = random.sample(user_ratings.keys(),1)[0]\n",
    "        i = random.sample(user_ratings[u],1)[0]\n",
    "        #test数据集里的数据不能作为训练使用，所以要另外取新值\n",
    "        while i==user_ratings_test[u]:\n",
    "            i = random.sample(user_ratings[u],1)[0]\n",
    "\n",
    "        j = random.randint(1,item_count)\n",
    "        while j in user_ratings[u]:\n",
    "            j = random.randint(1,item_count)\n",
    "\n",
    "        t.append([u,i,j])\n",
    "\n",
    "    return np.asarray(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_test_batch(user_ratings,user_ratings_test,item_count):\n",
    "    \"\"\"\n",
    "    对于每个用户u，它的评分电影i是我们在user_ratings_test中随机抽取的，它的j是用户u部分没有评分过的论文集合，\n",
    "    比如用户有n个评分过的论文，那么就从总论文集中抽取n个未评分过的论文作为j\n",
    "    \"\"\"\n",
    "    for u in user_ratings.keys():\n",
    "        num=len(user_ratings[u])\n",
    "        t = []\n",
    "        i = user_ratings_test[u]\n",
    "        for count in range(num):\n",
    "            j = random.randint(1,item_count)\n",
    "            if not(j in user_ratings[u]):\n",
    "                t.append([u,i,j])\n",
    "            else:\n",
    "                count-=1\n",
    "        yield np.asarray(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4343"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_ratings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bpr_mf(user_count,item_count,hidden_dim):\n",
    "    #hidden_dim是我们矩阵分解的隐含维度k\n",
    "    \n",
    "    #预先给三个参数赋予占位，分配必要的内存，等运行模型的时候通过feed_dict喂入数据\n",
    "    u = tf.placeholder(tf.int32,[None])\n",
    "    i = tf.placeholder(tf.int32,[None])\n",
    "    j = tf.placeholder(tf.int32,[None])\n",
    "\n",
    "    #创建新的tensorflow遍历，shape为count+1到hiddendim\n",
    "    #创建的是 正态分布初始化器 均值0 方差0.1\n",
    "    user_emb_w = tf.get_variable(\"user_emb_w\", [user_count + 1, hidden_dim],\n",
    "                                 initializer=tf.random_normal_initializer(0, 0.1))\n",
    "    item_emb_w = tf.get_variable(\"item_emb_w\", [item_count + 1, hidden_dim],\n",
    "                                 initializer=tf.random_normal_initializer(0, 0.1))\n",
    "\n",
    "    #选取一个张量里面索引对应的元素\n",
    "    #u,i,j是索引,user_emb_w等是张量\n",
    "    u_emb = tf.nn.embedding_lookup(user_emb_w, u)\n",
    "    i_emb = tf.nn.embedding_lookup(item_emb_w, i)\n",
    "    j_emb = tf.nn.embedding_lookup(item_emb_w, j)\n",
    "\n",
    "    #MF predict:u_i>u_j\n",
    "    #multiply 相同位置的元素相乘\n",
    "    #reduce_sum 计算张量沿着某一维度的和\n",
    "    #keepdims是否保持原有张量的维度\n",
    "    x = tf.reduce_sum(tf.multiply(u_emb,(i_emb-j_emb)),1,keep_dims=True)\n",
    "\n",
    "    \n",
    "    #每个用户的AUC（AUC是指ROC曲线下的面积，TP越大，ROC曲线越上凸，算法分类效果越优秀）\n",
    "    #average AUC = mean( auc for each user in test set)\n",
    "    mf_auc = tf.reduce_mean(tf.to_float(x>0))\n",
    "\n",
    "    #add_n 列表的元素相加\n",
    "    l2_norm = tf.add_n([\n",
    "        tf.reduce_sum(tf.multiply(u_emb, u_emb)),\n",
    "        tf.reduce_sum(tf.multiply(i_emb, i_emb)),\n",
    "        tf.reduce_sum(tf.multiply(j_emb, j_emb))\n",
    "    ])\n",
    "\n",
    "    #损失函数\n",
    "    regulation_rate = 0.0001\n",
    "    bprloss = regulation_rate * l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(x)))\n",
    "\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(bprloss)\n",
    "    return u, i, j, mf_auc, bprloss, train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#清除互动为1的用户后，需要对用户从0-4343进行一个重新排序\n",
    "#第一列是原始用户对应序号，第二列是从0开始排序后的序号\n",
    "user_temp=[]\n",
    "count=0\n",
    "for u in user_ratings:\n",
    "    user_temp.append([u,count])\n",
    "    count+=1\n",
    "    \n",
    "user_ratings_index={}\n",
    "count=0\n",
    "for u in user_ratings:\n",
    "    user_ratings_index[count]=user_ratings[u]\n",
    "    count+=1\n",
    "    \n",
    "users_temp=[]\n",
    "for u in user_ratings_index:\n",
    "    users_temp.append(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ratings_test = generate_test(user_ratings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "bpr_loss: 0.7236369838831925\n",
      "_train_op\n",
      "test_loss:  0.69467235 test_auc:  0.49854217610752327\n",
      "\n",
      "epoch: 2\n",
      "bpr_loss: 0.7229975729638229\n",
      "_train_op\n",
      "test_loss:  0.7084677 test_auc:  0.4981000391020599\n",
      "\n",
      "epoch: 3\n",
      "bpr_loss: 0.7223282952646323\n",
      "_train_op\n",
      "test_loss:  0.6987856 test_auc:  0.496151626918953\n",
      "\n",
      "Variable:  user_emb_w:0\n",
      "Shape:  (4344, 20)\n",
      "[[ 0.07407623 -0.08236344  0.20756564 ... -0.15193674 -0.08908212\n",
      "  -0.07115918]\n",
      " [ 0.04854294  0.04909178  0.11735984 ... -0.04734726  0.08562405\n",
      "   0.11522461]\n",
      " [-0.02148025 -0.03209087  0.08466808 ...  0.10490572 -0.07317357\n",
      "   0.10038902]\n",
      " ...\n",
      " [ 0.09304229 -0.05721299 -0.17697962 ...  0.09186146 -0.09449738\n",
      "   0.03842133]\n",
      " [-0.02151117  0.08202858 -0.0291393  ...  0.00493528  0.13892643\n",
      "  -0.25313568]\n",
      " [ 0.06014761  0.11454549  0.1993236  ... -0.1021769   0.00584623\n",
      "  -0.06821931]]\n",
      "Variable:  item_emb_w:0\n",
      "Shape:  (737768, 20)\n",
      "[[-0.01768387 -0.17980294 -0.0766371  ...  0.22600105 -0.14664263\n",
      "  -0.09697448]\n",
      " [-0.0639381  -0.01833209  0.03144683 ...  0.00346424  0.18578215\n",
      "   0.00083119]\n",
      " [ 0.15837403 -0.00989952  0.18662797 ... -0.11257127  0.01627197\n",
      "   0.12493929]\n",
      " ...\n",
      " [-0.13440527 -0.06436712  0.03395337 ...  0.06488209  0.00946386\n",
      "  -0.02100194]\n",
      " [-0.01190213 -0.12214206 -0.1151367  ...  0.23577553  0.0150328\n",
      "   0.03688189]\n",
      " [ 0.00813513 -0.03379352 -0.02075781 ...  0.0081152   0.03116548\n",
      "  -0.12534562]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#  0号用户对这个用户对所有电影的预测评分\\nsession1 = tf.Session()\\nu1_dim = tf.expand_dims(values[0][0], 0)\\nu1_all = tf.matmul(u1_dim, values[1],transpose_b=True)\\nresult_1 = session1.run(u1_all)\\nprint (result_1)\\n\\nprint(\"以下是给用户0的推荐：\")\\np = np.squeeze(result_1)\\np[np.argsort(p)[:-5]] = 0\\nfor index in range(len(p)):\\n    if p[index] != 0:\\n        print (index, p[index])'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    u,i,j,mf_auc,bprloss,train_op = bpr_mf(len(users_temp),len(artical_list),20)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(1,4):\n",
    "        _batch_bprloss = 0\n",
    "        for k in range(1,5000):# uniform samples from training set\n",
    "            uij = generate_train_batch(user_ratings_index,user_ratings_test,len(artical_list))\n",
    "            \n",
    "            _bprloss,_train_op = sess.run([bprloss,train_op],\n",
    "                                          feed_dict={u:uij[:,0],i:uij[:,1],j:uij[:,2]})\n",
    "            \n",
    "            _batch_bprloss += _bprloss\n",
    "\n",
    "        print(\"epoch:\",epoch)\n",
    "        print(\"bpr_loss:\",_batch_bprloss / k)\n",
    "        print(\"_train_op\")\n",
    "\n",
    "        user_count = 0\n",
    "        _auc_sum = 0.0\n",
    "\n",
    "        # each batch will return only one user's auc\n",
    "        for t_uij in generate_test_batch(user_ratings_index, user_ratings_test, len(artical_list)):\n",
    "            _auc, _test_bprloss = sess.run([mf_auc, bprloss],\n",
    "                                              feed_dict={u: t_uij[:, 0], i: t_uij[:, 1], j: t_uij[:, 2]}\n",
    "                                              )\n",
    "            user_count += 1\n",
    "            _auc_sum += _auc\n",
    "        print(\"test_loss: \", _test_bprloss, \"test_auc: \", _auc_sum / user_count)\n",
    "        print(\"\")\n",
    "    variable_names = [v.name for v in tf.trainable_variables()]\n",
    "    values = sess.run(variable_names)\n",
    "    for k, v in zip(variable_names, values):\n",
    "        print(\"Variable: \", k)\n",
    "        print(\"Shape: \", v.shape)\n",
    "        print(v)\n",
    "\n",
    "#这里取了k=20，迭代次数3\n",
    "        \n",
    "#输出的W,H矩阵分别在values[0]和values[1]中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00846129 -0.02636753  0.01312796 ... -0.0118585   0.00779091\n",
      "   0.07868302]]\n"
     ]
    }
   ],
   "source": [
    "#0号用户对这个用户对所有电影的预测评分\n",
    "session1 = tf.Session()\n",
    "#expand_dims扩大指定维数 原来values[0][0]为（20，）的数组 变为(1,20)\n",
    "u1_dim = tf.expand_dims(values[0][0], 0)\n",
    "\n",
    "#matmul a、b矩阵相乘 transpose_b：如果 True,b 在乘法之前转置\n",
    "u1_all = tf.matmul(u1_dim, values[1],transpose_b=True)\n",
    "\n",
    "#计算用户0对所有商品的排序\n",
    "result_1 = session1.run(u1_all)\n",
    "print (result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是给用户0的推荐：\n",
      "58664 0.22749951\n",
      "231607 0.21820468\n",
      "360229 0.22035974\n",
      "486676 0.22655472\n",
      "583043 0.21965653\n"
     ]
    }
   ],
   "source": [
    "print(\"以下是给用户0的推荐：\")\n",
    "#squeeze 将结果矩阵的第一维去掉，去掉外面一个框\n",
    "p = np.squeeze(result_1)\n",
    "\n",
    "#argsort 返回数组值从小到大的索引值\n",
    "#把大小除了最大五个以外的p里的其他索引对应的值都设为0\n",
    "p[np.argsort(p)[:-5]] = 0\n",
    "\n",
    "#遍历p中的全部索引，只要值不为0，就输出索引和对应的索引值\n",
    "for index in range(len(p)):\n",
    "    if p[index] != 0:\n",
    "        print (index, p[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
